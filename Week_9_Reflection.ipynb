{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Combine a rule-based and a machine-learning chatbot (like those of the example code),using rules and training data of your choice (you may retain the example setup if you wish) to implement a bot that answers clear-cut situations based on rules and defaults to the responses from a fitted neural network when no rule matches. Interact with it and discuss the strengths and the weaknesses of your bot. Please include code snippets and an example dialogue in your response."
      ],
      "metadata": {
        "id": "QmVW6I6fZMMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        " \n",
        "# Data to be written\n",
        "intents = {\n",
        "    'intents':[{'tag': 'greeting',\n",
        "                'patterns': ['Hi', 'Hello', 'Howdy', 'How do you do', 'Hey', 'Hi there', 'Good Morning',\n",
        "                             'Good Afternoon', 'Good evening', 'Yo, what\\'s up', 'How is it going', 'How are you doing',\n",
        "                             'How goes it','How\\'s life','Sup', 'Whazzup', 'G\\'day mate', 'Hiya'], \n",
        "                'responses':['Hello', 'Hi', 'Hi Hi', 'Good Morning',\n",
        "                             'Good Afternoon', 'Good evening', 'No much and you', 'Life is amazing', 'Good, thank you, and you', \n",
        "                             'Meh', 'Nah', 'Wonderful',\n",
        "                             'Enchanting', 'It\\'s so amazing that you can\\'t even imagine', 'G\\'day mate', 'Hiya','A big HELLO to you too']},\n",
        "               {'tag': 'goodbye',\n",
        "               'patterns': ['Bye', 'Good bye', 'Ciao', 'Ciao ciao', 'auf Wiedersehen','See you later', 'See you soon', 'Hope to see you soon',\n",
        "                            'Talk to you later', 'Gotta go','Take it easy','I\\'m off', 'Have a nice one', 'Have a good day', 'Good Day',\n",
        "                            'Good Day Sweetie', 'Have a nice day', 'I look forward to chatting with you again', 'Until then', 'Take care', \n",
        "                            'Good night', 'Later', 'Laters', 'Catch you later', 'Peace', 'Peace out', 'I\\'m out', 'I gotta jet ', \n",
        "                            'I gotta take off', 'I gotta hit the road', 'I gotta head out','Sayonara', 'Arrivederci', 'Adios' ],\n",
        "                'responses':['See you later', 'Have a nice day', 'Sweet Dreams', 'Bye' 'Good bye', 'Come back again', 'Same here', \n",
        "                             'Peace', 'Peace out',\n",
        "                             'Sayonara', 'Arrivederci', 'Adios','Good Day Sweetie',  'Have a nice one', 'Have a good day', \n",
        "                             'Good Day', 'May the force be with you',\n",
        "                             'يلاباي', 'Ciao','Ciao ciao','May god be with you ','ttyl', 'May our paths cross again','Bye bye', \n",
        "                             'Bye for now','Until the next time',\n",
        "                             'Bon vent', 'À la revoyure']},\n",
        "               {'tag':'thanks',\n",
        "                'patterns':['Thanks', 'Thank you', 'Thank you very much', 'That\\'s very helpful', 'That\\'s very helpful', 'That\\'s very insightful',\n",
        "                            'Thank you for the help', 'Thanks for the help', 'Danke', 'Amazing', 'Much obliged', 'Thanks for having my back', 'Cheers',\n",
        "                            'Many thanks', 'Thx', 'I am so grateful', 'Highly appreciate it', 'I could not have done it without you', 'I owe you one',\n",
        "                            'I owe you a big one', 'Please accept my deepest gratitude', 'This has been such a blessing', 'I can\\'t thank you enough', \n",
        "                            'That\\'s so kind of you', 'You are too kind', 'Thank you for taking your time to help me', 'Your support means the word', \n",
        "                            'Your support means the world to me','Mille Grazie', 'Merci', 'I sncerely applaud you', 'I am forever indebted', \n",
        "                            'I am blown away by your kindness', 'I want to acknowledge how much you have done', 'Thanks in advance', 'I stand in recognition', \n",
        "                            'I have to give credit where it is due'],\n",
        "                'responses':['Happy to help!', 'Any time!', 'My pleasure', 'You are most welcome!', 'The pleasure is mine!','No Biggie', 'No problem',\n",
        "                             'I am glad to help you in anyway I can', 'I am glad', 'Cheers', 'Wunderbar!', 'You are welcome', 'Amazing']},\n",
        "               {'tag':'about',\n",
        "                'patterns':['Who are you?', 'What are you?','Who is this?', 'Who am I chatting with', 'With whom am I chatting?', 'To whom am I speaking?',\n",
        "                            'Who might you be?', 'Are you a human?', 'Are you a chatbot?', 'What is your name?', 'How may I address you?', 'How should I call you?',\n",
        "                            'Where am I?'],\n",
        "                'responses':['Oh hello there, I am Alexandria, your bot assistant!', 'Hello, I am David, your loyal Artificial Intelligent servant!', 'Call me Betty!', \n",
        "                             'You are here at our automated customer service, I am John, your AI bot assistant', 'I am not human, I am Alexandria, your bot assistant', \n",
        "                             'Call me Johan!', 'My name is Hrafn!']},\n",
        "               {'tag': 'help',\n",
        "                'patterns':['Could you help me?', 'Could you help me with something?', 'Can you help me with something?', 'Give me a hand please', \n",
        "                            'Can you help?', 'What can you do for me?', 'I need a support', 'I desprerately need your help', 'Support me please!', \n",
        "                            'Oh Gosh, I need your help for something!', 'Help, help!', 'Can you do something for me, please?'],\n",
        "                'responses':[\"Tell me how can assist you\", \"Tell me your problem to assist you\", \"Yes Sure, How can I support you\",'How may I be of service?',\n",
        "                             'What do you want me to do?', 'Pray!', 'Pray tell','What\\'s up?', 'Yes, what?', 'Yes, sure', 'Do tell, please!', 'Ok, what type of services do you require?',\n",
        "                             'Yep, what\\'s the matter?', 'Gladly, do tell!', 'It will be my pleasure!', 'I always have time for you, my liege!', 'Alright, what do you need?', \n",
        "                             'What is it?', 'Ok', 'Okay', 'Sure', 'Certainly', 'undoubtedly!','Unquestionably!', 'Yaaaas!']},\n",
        "               {\"tag\": \"createaccount\",\n",
        "                \"patterns\": [\"I need to create a new account\", \"how to open a new account\", \"I want to create an account\", \n",
        "                             \"can you create an account for me\", \"how to open a new account\"],\n",
        "                \"responses\": [\"You can just easily create a new account from our web site\",\n",
        "                              \"Just go to our web site and follow the guidelines to create a new account\"]},\n",
        "               {'tag':'billing',\n",
        "                'patterns':['Can you check my last payment,please?', 'Why is my payment not going through?', 'What is wrong with your billing system?', \n",
        "                            'I am having difficulties to make a payment', 'Can I make a payment here?', 'Can I make a payment through your website?',\n",
        "                            'Refund please!', 'Can I make a payment with my personal cheque?','My credit card is expired, I would like to update my billing info!',\n",
        "                            'There is a mistake on my bill for this month!', 'I have been over charged!', 'I demande a refund!!!', 'I would like to cancel my subscription, please!', \n",
        "                            'For some reason, I have not received this month\\'s bill yet, What\\'s going on?', 'Where can I make a payment, through my financial institute or by phone?', \n",
        "                            'I can\\'t understand my bill, I need some explaination, please!', 'Can you help me to check my current balance, please?'],\n",
        "                'responses':['I am so sorry to hear that. Let me check it out for you.', 'I understand totaly, I will help you in anyway I can.',\n",
        "                             'I am sorry for the inconvenience, I will try to sort it out for you.', 'No problem, I will pull your info at once.', \n",
        "                             'No problem, right away!', 'Certainly, I will looking into it immediately!', 'For the refund, I will direct you to the billing department. A moment please.', \n",
        "                             'A moment please.', 'Right away!', 'Of course.', 'Absolutely', 'For more info, please dial our tolfree number at 1-800-999-9999.',\n",
        "                             'I am sorry, I can\\'t process your info at this time, please contact our customer service at 1-888-9999-9999.', \n",
        "                             'Sorry, I can\\'t help you with your problem, you must contact your finacal institute for more information.', \n",
        "                             'Sorry, your credit card has been declined. Perhaps, you can try to process your payment with a different credit card.', \n",
        "                             'It is very unfortunate that our system is down at the moment, please contact us again at a later moment.', \n",
        "                             'I am sorry, but we do not accept Union Pay!', 'Your current balance is 465 dollars, and your billing cycle is from 2022-10-15 to 2022-11-15.', \n",
        "                             'You have a due of 115 dollars, would you like to make a payment right now?']},\n",
        "               {\"tag\": \"complaint\",\n",
        "                \"patterns\": [\"I have a complaint? \", \"I want to raise a complaint\", \"I would like to make a complaint about your service\",\n",
        "                             'I would like to get in touch with a manager regarding a complaint, please!', 'Blimey, I am here to file a complaint.', \n",
        "                             'WTF is wrong with your service, it\\'s disgusting. I need to make a complaint!', 'You guys are a fucking piece of shit, I want my money back!', \n",
        "                             'Horrible service, I would like to file a compalint.', 'I would like to speak to a manager immediately!!!', 'Where is my freaking product?',\n",
        "                             'Get me someone who is not incompetent, immediatly!', 'Fuck you!', 'A piece of shit!', 'You guys are a bunch of thieves!', 'You\\'ve lost my package!', \n",
        "                             'I am so freaking pissed, What the fuck is going on with my order?', 'Freaking hell, I have been waiting on the phone for 45 minutes!'],\n",
        "                \"responses\": [\"Please provide us your complaint in order to assist you\", \"Please mention your complaint, we will reach you and sorry for any inconvenience caused\",\n",
        "                              'We are very sorry to hear that, we will assist you immediately.', 'I will direct your complaint to our customer satisfaction department right away.',\n",
        "                              'You are our priority, a moment please!', 'I will direct you to our shipping department, please wait.', 'We do not tolerate profanity spiel, please try it again!',\n",
        "                              'What is the subject of your complaint?', 'To speak to a manager in charge, please dial 1-880-666-6666.', 'Thank your for your patience, our shipping department is trying to locate your order.',\n",
        "                              'Thank your for your patience. Your order is at the custom, please visit https://www.cbsa-asfc.gc.ca/menu-eng.html for more details.']}]}\n",
        "               \n",
        "\n"
      ],
      "metadata": {
        "id": "rTSRw0kkvNI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('json_data.json', 'w') as outfile:\n",
        "    json.dump(intents, outfile, indent=4)   # <-- change new_intents to intents\n",
        "\n",
        "with open('json_data.json') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "print(data['intents'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihvdp_IJkeEp",
        "outputId": "50249208-44f7-49c0-9ec8-99146c458032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'tag': 'greeting', 'patterns': ['Hi', 'Hello', 'Howdy', 'How do you do', 'Hey', 'Hi there', 'Good Morning', 'Good Afternoon', 'Good evening', \"Yo, what's up\", 'How is it going', 'How are you doing', 'How goes it', \"How's life\", 'Sup', 'Whazzup', \"G'day mate\", 'Hiya'], 'responses': ['Hello', 'Hi', 'Hi Hi', 'Good Morning', 'Good Afternoon', 'Good evening', 'No much and you', 'Life is amazing', 'Good, thank you, and you', 'Meh', 'Nah', 'Wonderful', 'Enchanting', \"It's so amazing that you can't even imagine\", \"G'day mate\", 'Hiya', 'A big HELLO to you too']}, {'tag': 'goodbye', 'patterns': ['Bye', 'Good bye', 'Ciao', 'Ciao ciao', 'auf Wiedersehen', 'See you later', 'See you soon', 'Hope to see you soon', 'Talk to you later', 'Gotta go', 'Take it easy', \"I'm off\", 'Have a nice one', 'Have a good day', 'Good Day', 'Good Day Sweetie', 'Have a nice day', 'I look forward to chatting with you again', 'Until then', 'Take care', 'Good night', 'Later', 'Laters', 'Catch you later', 'Peace', 'Peace out', \"I'm out\", 'I gotta jet ', 'I gotta take off', 'I gotta hit the road', 'I gotta head out', 'Sayonara', 'Arrivederci', 'Adios'], 'responses': ['See you later', 'Have a nice day', 'Sweet Dreams', 'ByeGood bye', 'Come back again', 'Same here', 'Peace', 'Peace out', 'Sayonara', 'Arrivederci', 'Adios', 'Good Day Sweetie', 'Have a nice one', 'Have a good day', 'Good Day', 'May the force be with you', 'يلاباي', 'Ciao', 'Ciao ciao', 'May god be with you ', 'ttyl', 'May our paths cross again', 'Bye bye', 'Bye for now', 'Until the next time', 'Bon vent', 'À la revoyure']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', 'Thank you very much', \"That's very helpful\", \"That's very helpful\", \"That's very insightful\", 'Thank you for the help', 'Thanks for the help', 'Danke', 'Amazing', 'Much obliged', 'Thanks for having my back', 'Cheers', 'Many thanks', 'Thx', 'I am so grateful', 'Highly appreciate it', 'I could not have done it without you', 'I owe you one', 'I owe you a big one', 'Please accept my deepest gratitude', 'This has been such a blessing', \"I can't thank you enough\", \"That's so kind of you\", 'You are too kind', 'Thank you for taking your time to help me', 'Your support means the word', 'Your support means the world to me', 'Mille Grazie', 'Merci', 'I sncerely applaud you', 'I am forever indebted', 'I am blown away by your kindness', 'I want to acknowledge how much you have done', 'Thanks in advance', 'I stand in recognition', 'I have to give credit where it is due'], 'responses': ['Happy to help!', 'Any time!', 'My pleasure', 'You are most welcome!', 'The pleasure is mine!', 'No Biggie', 'No problem', 'I am glad to help you in anyway I can', 'I am glad', 'Cheers', 'Wunderbar!', 'You are welcome', 'Amazing']}, {'tag': 'about', 'patterns': ['Who are you?', 'What are you?', 'Who is this?', 'Who am I chatting with', 'With whom am I chatting?', 'To whom am I speaking?', 'Who might you be?', 'Are you a human?', 'Are you a chatbot?', 'What is your name?', 'How may I address you?', 'How should I call you?', 'Where am I?'], 'responses': ['Oh hello there, I am Alexandria, your bot assistant!', 'Hello, I am David, your loyal Artificial Intelligent servant!', 'Call me Betty!', 'You are here at our automated customer service, I am John, your AI bot assistant', 'I am not human, I am Alexandria, your bot assistant', 'Call me Johan!', 'My name is Hrafn!']}, {'tag': 'help', 'patterns': ['Could you help me?', 'Could you help me with something?', 'Can you help me with something?', 'Give me a hand please', 'Can you help?', 'What can you do for me?', 'I need a support', 'I desprerately need your help', 'Support me please!', 'Oh Gosh, I need your help for something!', 'Help, help!', 'Can you do something for me, please?'], 'responses': ['Tell me how can assist you', 'Tell me your problem to assist you', 'Yes Sure, How can I support you', 'How may I be of service?', 'What do you want me to do?', 'Pray!', 'Pray tell', \"What's up?\", 'Yes, what?', 'Yes, sure', 'Do tell, please!', 'Ok, what type of services do you require?', \"Yep, what's the matter?\", 'Gladly, do tell!', 'It will be my pleasure!', 'I always have time for you, my liege!', 'Alright, what do you need?', 'What is it?', 'Ok', 'Okay', 'Sure', 'Certainly', 'undoubtedly!', 'Unquestionably!', 'Yaaaas!']}, {'tag': 'createaccount', 'patterns': ['I need to create a new account', 'how to open a new account', 'I want to create an account', 'can you create an account for me', 'how to open a new account'], 'responses': ['You can just easily create a new account from our web site', 'Just go to our web site and follow the guidelines to create a new account']}, {'tag': 'billing', 'patterns': ['Can you check my last payment,please?', 'Why is my payment not going through?', 'What is wrong with your billing system?', 'I am having difficulties to make a payment', 'Can I make a payment here?', 'Can I make a payment through your website?', 'Refund please!', 'Can I make a payment with my personal cheque?', 'My credit card is expired, I would like to update my billing info!', 'There is a mistake on my bill for this month!', 'I have been over charged!', 'I demande a refund!!!', 'I would like to cancel my subscription, please!', \"For some reason, I have not received this month's bill yet, What's going on?\", 'Where can I make a payment, through my financial institute or by phone?', \"I can't understand my bill, I need some explaination, please!\", 'Can you help me to check my current balance, please?'], 'responses': ['I am so sorry to hear that. Let me check it out for you.', 'I understand totaly, I will help you in anyway I can.', 'I am sorry for the inconvenience, I will try to sort it out for you.', 'No problem, I will pull your info at once.', 'No problem, right away!', 'Certainly, I will looking into it immediately!', 'For the refund, I will direct you to the billing department. A moment please.', 'A moment please.', 'Right away!', 'Of course.', 'Absolutely', 'For more info, please dial our tolfree number at 1-800-999-9999.', \"I am sorry, I can't process your info at this time, please contact our customer service at 1-888-9999-9999.\", \"Sorry, I can't help you with your problem, you must contact your finacal institute for more information.\", 'Sorry, your credit card has been declined. Perhaps, you can try to process your payment with a different credit card.', 'It is very unfortunate that our system is down at the moment, please contact us again at a later moment.', 'I am sorry, but we do not accept Union Pay!', 'Your current balance is 465 dollars, and your billing cycle is from 2022-10-15 to 2022-11-15.', 'You have a due of 115 dollars, would you like to make a payment right now?']}, {'tag': 'complaint', 'patterns': ['I have a complaint? ', 'I want to raise a complaint', 'I would like to make a complaint about your service', 'I would like to get in touch with a manager regarding a complaint, please!', 'Blimey, I am here to file a complaint.', \"WTF is wrong with your service, it's disgusting. I need to make a complaint!\", 'You guys are a fucking piece of shit, I want my money back!', 'Horrible service, I would like to file a compalint.', 'I would like to speak to a manager immediately!!!', 'Where is my freaking product?', 'Get me someone who is not incompetent, immediatly!', 'Fuck you!', 'A piece of shit!', 'You guys are a bunch of thieves!', \"You've lost my package!\", 'I am so freaking pissed, What the fuck is going on with my order?', 'Freaking hell, I have been waiting on the phone for 45 minutes!'], 'responses': ['Please provide us your complaint in order to assist you', 'Please mention your complaint, we will reach you and sorry for any inconvenience caused', 'We are very sorry to hear that, we will assist you immediately.', 'I will direct your complaint to our customer satisfaction department right away.', 'You are our priority, a moment please!', 'I will direct you to our shipping department, please wait.', 'We do not tolerate profanity spiel, please try it again!', 'What is the subject of your complaint?', 'To speak to a manager in charge, please dial 1-880-666-6666.', 'Thank your for your patience, our shipping department is trying to locate your order.', 'Thank your for your patience. Your order is at the custom, please visit https://www.cbsa-asfc.gc.ca/menu-eng.html for more details.']}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.optimizers import SGD\n",
        "import random"
      ],
      "metadata": {
        "id": "zSBbvHjmilT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea7ca12-5899-429e-e99d-cbf981a74a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words=[]\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = ['?', '!']\n",
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "\n",
        "        # take each word and tokenize it\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        words.extend(w)\n",
        "        # adding documents\n",
        "        documents.append((w, intent['tag']))\n",
        "\n",
        "        # adding classes to our class list\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])    \n",
        "\n"
      ],
      "metadata": {
        "id": "NJsxcCNvipQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[:10]"
      ],
      "metadata": {
        "id": "-CwqCv7wjd_Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd5f4eb-fa0f-4ddf-81ef-3a5818ea4a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hi', 'Hello', 'Howdy', 'How', 'do', 'you', 'do', 'Hey', 'Hi', 'there']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "litFWaxICn9l",
        "outputId": "018de5d8-20aa-4c09-a734-0d3ed49d7d62"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['greeting',\n",
              " 'goodbye',\n",
              " 'thanks',\n",
              " 'about',\n",
              " 'help',\n",
              " 'createaccount',\n",
              " 'billing',\n",
              " 'complaint']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvW8Spe8Cun6",
        "outputId": "12b4d1c7-8fc0-455f-b180-2f306801764d"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(['Hi'], 'greeting'),\n",
              " (['Hello'], 'greeting'),\n",
              " (['Howdy'], 'greeting'),\n",
              " (['How', 'do', 'you', 'do'], 'greeting'),\n",
              " (['Hey'], 'greeting'),\n",
              " (['Hi', 'there'], 'greeting'),\n",
              " (['Good', 'Morning'], 'greeting'),\n",
              " (['Good', 'Afternoon'], 'greeting'),\n",
              " (['Good', 'evening'], 'greeting'),\n",
              " (['Yo', ',', 'what', \"'s\", 'up'], 'greeting')]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "classes = sorted(list(set(classes)))\n",
        "\n",
        "print (len(documents), \"documents\")\n",
        "\n",
        "print (len(classes), \"classes\", classes)\n",
        "\n",
        "print (len(words), \"unique lemmatized words\", words)\n",
        "\n",
        "\n",
        "pickle.dump(words,open('words.pkl','wb'))\n",
        "pickle.dump(classes,open('classes.pkl','wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glnLg8qFCz0L",
        "outputId": "1429c186-9cc2-4990-9d08-a4c9f429cb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153 documents\n",
            "8 classes ['about', 'billing', 'complaint', 'createaccount', 'goodbye', 'greeting', 'help', 'thanks']\n",
            "251 unique lemmatized words [\"'m\", \"'s\", \"'ve\", ',', '.', '45', 'a', 'about', 'accept', 'account', 'acknowledge', 'address', 'adios', 'advance', 'afternoon', 'again', 'am', 'amazing', 'an', 'applaud', 'appreciate', 'are', 'arrivederci', 'auf', 'away', 'back', 'balance', 'be', 'been', 'big', 'bill', 'billing', 'blessing', 'blimey', 'blown', 'bunch', 'by', 'bye', 'ca', 'call', 'can', 'cancel', 'card', 'care', 'catch', 'charged', 'chatbot', 'chatting', 'check', 'cheer', 'cheque', 'ciao', 'compalint', 'complaint', 'could', 'create', 'credit', 'current', 'danke', 'day', 'deepest', 'demande', 'desprerately', 'difficulty', 'disgusting', 'do', 'doing', 'done', 'due', 'easy', 'enough', 'evening', 'expired', 'explaination', 'file', 'financial', 'for', 'forever', 'forward', 'freaking', 'fuck', 'fucking', \"g'day\", 'get', 'give', 'go', 'going', 'good', 'gosh', 'got', 'grateful', 'gratitude', 'grazie', 'guy', 'ha', 'hand', 'have', 'having', 'head', 'hell', 'hello', 'help', 'helpful', 'here', 'hey', 'hi', 'highly', 'hit', 'hiya', 'hope', 'horrible', 'how', 'howdy', 'human', 'i', 'immediately', 'immediatly', 'in', 'incompetent', 'indebted', 'info', 'insightful', 'institute', 'is', 'it', 'jet', 'kind', 'kindness', 'last', 'later', 'laters', 'life', 'like', 'look', 'lost', 'make', 'manager', 'many', 'mate', 'may', 'me', 'mean', 'merci', 'might', 'mille', 'minute', 'mistake', 'money', 'month', 'morning', 'much', 'my', \"n't\", 'name', 'need', 'new', 'nice', 'night', 'not', 'obliged', 'of', 'off', 'oh', 'on', 'one', 'open', 'or', 'order', 'out', 'over', 'owe', 'package', 'payment', 'peace', 'personal', 'phone', 'piece', 'pissed', 'please', 'product', 'raise', 'reason', 'received', 'recognition', 'refund', 'regarding', 'road', 'sayonara', 'see', 'service', 'shit', 'should', 'sncerely', 'so', 'some', 'someone', 'something', 'soon', 'speak', 'speaking', 'stand', 'subscription', 'such', 'sup', 'support', 'sweetie', 'system', 'ta', 'take', 'taking', 'talk', 'thank', 'thanks', 'that', 'the', 'then', 'there', 'thief', 'this', 'through', 'thx', 'time', 'to', 'too', 'touch', 'understand', 'until', 'up', 'update', 'very', 'waiting', 'want', 'website', 'what', 'whazzup', 'where', 'who', 'whom', 'why', 'wiedersehen', 'with', 'without', 'word', 'world', 'would', 'wrong', 'wtf', 'yet', 'yo', 'you', 'your']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training = []\n",
        "output_empty = [0] * len(classes)\n",
        "for doc in documents:\n",
        "    # initializing bag of words\n",
        "    bag = []\n",
        "    # list of tokenized words for the pattern\n",
        "    pattern_words = doc[0]\n",
        "    # lemmatize each word - create base word, in attempt to represent related words\n",
        "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "    # create our bag of words array with 1, if word match found in current pattern\n",
        "    for w in words:\n",
        "        bag.append(1) if w in pattern_words else bag.append(0)\n",
        "\n",
        "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "\n",
        "    training.append([bag, output_row])\n",
        "# shuffle our features and turn into np.array\n",
        "random.shuffle(training)\n",
        "training = np.array(training,dtype=object)\n",
        "# create train and test lists. X - patterns, Y - intents\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])\n",
        "print(\"Training data created\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMAfE_8dDCbb",
        "outputId": "98367ba8-09ef-4401-b895-b7e6c2da38dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))\n",
        "\n",
        "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
        "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "#fitting and saving the model\n",
        "hist = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)\n",
        "model.save('chatbot_model.h5', hist)\n",
        "\n",
        "print(\"model created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFFLN0zNDzNW",
        "outputId": "702611ba-fea5-4d8d-dbc5-d49ed70a58a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "31/31 [==============================] - 1s 2ms/step - loss: 2.0209 - accuracy: 0.2418\n",
            "Epoch 2/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.9298 - accuracy: 0.2614\n",
            "Epoch 3/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.7693 - accuracy: 0.3399\n",
            "Epoch 4/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.6445 - accuracy: 0.4183\n",
            "Epoch 5/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.5145 - accuracy: 0.4641\n",
            "Epoch 6/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.3390 - accuracy: 0.5294\n",
            "Epoch 7/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.1876 - accuracy: 0.5621\n",
            "Epoch 8/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 1.0571 - accuracy: 0.6536\n",
            "Epoch 9/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.8009 - accuracy: 0.7124\n",
            "Epoch 10/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.7332 - accuracy: 0.7778\n",
            "Epoch 11/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.7647\n",
            "Epoch 12/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.8497\n",
            "Epoch 13/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8366\n",
            "Epoch 14/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.8105\n",
            "Epoch 15/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.9085\n",
            "Epoch 16/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.9412\n",
            "Epoch 17/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.9281\n",
            "Epoch 18/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.9281\n",
            "Epoch 19/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.9412\n",
            "Epoch 20/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.9020\n",
            "Epoch 21/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.2399 - accuracy: 0.9150\n",
            "Epoch 22/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.9477\n",
            "Epoch 23/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.2070 - accuracy: 0.9216\n",
            "Epoch 24/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9542\n",
            "Epoch 25/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.1509 - accuracy: 0.9673\n",
            "Epoch 26/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.9804\n",
            "Epoch 27/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.1215 - accuracy: 0.9739\n",
            "Epoch 28/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.9804\n",
            "Epoch 29/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9608\n",
            "Epoch 30/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.9804\n",
            "Epoch 31/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9739\n",
            "Epoch 32/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0864 - accuracy: 0.9804\n",
            "Epoch 33/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9739\n",
            "Epoch 34/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9477\n",
            "Epoch 36/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9869\n",
            "Epoch 37/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9673\n",
            "Epoch 38/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0964 - accuracy: 0.9739\n",
            "Epoch 39/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0504 - accuracy: 0.9869\n",
            "Epoch 40/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9869\n",
            "Epoch 41/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 0.9804\n",
            "Epoch 42/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9869\n",
            "Epoch 43/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9935\n",
            "Epoch 44/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0808 - accuracy: 0.9608\n",
            "Epoch 45/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9804\n",
            "Epoch 46/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.9804\n",
            "Epoch 47/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9869\n",
            "Epoch 48/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.9869\n",
            "Epoch 49/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9869\n",
            "Epoch 50/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9804\n",
            "Epoch 51/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9869\n",
            "Epoch 52/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9804\n",
            "Epoch 53/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9869\n",
            "Epoch 54/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9869\n",
            "Epoch 55/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9804\n",
            "Epoch 56/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9869\n",
            "Epoch 59/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0597 - accuracy: 0.9869\n",
            "Epoch 61/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9869\n",
            "Epoch 62/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.9869\n",
            "Epoch 63/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9935\n",
            "Epoch 65/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9935\n",
            "Epoch 66/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.9869\n",
            "Epoch 68/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9869\n",
            "Epoch 70/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9869\n",
            "Epoch 71/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.9935\n",
            "Epoch 75/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9935\n",
            "Epoch 76/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9804\n",
            "Epoch 78/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9869\n",
            "Epoch 79/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 0.9804\n",
            "Epoch 80/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9935\n",
            "Epoch 81/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9869\n",
            "Epoch 82/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 0.9869\n",
            "Epoch 84/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9869\n",
            "Epoch 85/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.9935\n",
            "Epoch 87/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.9935\n",
            "Epoch 89/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9935\n",
            "Epoch 90/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9935\n",
            "Epoch 93/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9935\n",
            "Epoch 94/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9869\n",
            "Epoch 95/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9804\n",
            "Epoch 96/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9935\n",
            "Epoch 98/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9935\n",
            "Epoch 105/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9935\n",
            "Epoch 106/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9935\n",
            "Epoch 107/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9935\n",
            "Epoch 110/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9935\n",
            "Epoch 113/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9935\n",
            "Epoch 114/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9935\n",
            "Epoch 115/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9935\n",
            "Epoch 118/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9935\n",
            "Epoch 121/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9869\n",
            "Epoch 123/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9935\n",
            "Epoch 125/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9869\n",
            "Epoch 126/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9935\n",
            "Epoch 128/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9935\n",
            "Epoch 131/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9935\n",
            "Epoch 132/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9935\n",
            "Epoch 137/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9869\n",
            "Epoch 139/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9935\n",
            "Epoch 141/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9935\n",
            "Epoch 142/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9935\n",
            "Epoch 143/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9935\n",
            "Epoch 147/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9935\n",
            "Epoch 148/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.9935\n",
            "Epoch 149/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 0.9935\n",
            "Epoch 150/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9935\n",
            "Epoch 152/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9935\n",
            "Epoch 154/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9935\n",
            "Epoch 156/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9935\n",
            "Epoch 158/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.9935\n",
            "Epoch 161/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0126 - accuracy: 0.9935\n",
            "Epoch 162/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9935\n",
            "Epoch 164/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 0.9935\n",
            "Epoch 167/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9935\n",
            "Epoch 171/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9869\n",
            "Epoch 172/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9869\n",
            "Epoch 176/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.9869\n",
            "Epoch 177/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.9935\n",
            "Epoch 179/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.9935\n",
            "Epoch 181/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0138 - accuracy: 0.9935\n",
            "Epoch 185/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9935\n",
            "Epoch 186/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.9935\n",
            "Epoch 187/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9935\n",
            "Epoch 188/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9935\n",
            "Epoch 195/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9935\n",
            "Epoch 196/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9935\n",
            "Epoch 197/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "31/31 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.9935\n",
            "model created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "userinput = input('Write here to what you want the bot to respond: ')"
      ],
      "metadata": {
        "id": "TasalMacFTE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c1150a-62e9-4082-fde9-a9d76b6b2abe"
      },
      "execution_count": 25,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Write here to what you want the bot to respond: A piece of shit! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uw = set([ lemmatizer.lemmatize(w) for w in nltk.word_tokenize(userinput) ])\n",
        "BoW = [ 1 * (w in uw) for w in words ]\n",
        "print(len(BoW))\n",
        "threshold = 0.3 # discard unpromising results\n",
        "import tensorflow as tf\n",
        "datapoint = tf.convert_to_tensor(np.array([BoW]))\n",
        "p = model.predict(datapoint)[0] # predict just this one data point\n",
        "print(classes) # reminder\n",
        "for outcome, label in zip(p, classes):\n",
        "  if outcome > threshold: # could be a match\n",
        "    print(outcome, label)"
      ],
      "metadata": {
        "id": "1X_e9CXrFYyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c0f175-a46e-44e2-ed48-855c1d311263"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "251\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "['about', 'billing', 'complaint', 'createaccount', 'goodbye', 'greeting', 'help', 'thanks']\n",
            "1.0 complaint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best = np.argmax(p) # use the highest as our match\n",
        "chosen = classes[best] # the class to use to respond\n",
        "print(f'Chose class {chosen}')\n",
        "from random import choice # we pick one at random\n",
        "for i in intents['intents']:\n",
        "  if i['tag'] == chosen: \n",
        "    print(choice(i['responses']))\n",
        "    break"
      ],
      "metadata": {
        "id": "pDrSe-xLGd9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b812fb-18e1-45f6-b561-8268960c0752"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chose class complaint\n",
            "We do not tolerate profanity spiel, please try it again!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NUiXn_GbZbf5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}